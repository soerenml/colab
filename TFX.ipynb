{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFX.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhNcq4CNwXf230+Nw7Zfmz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soerenml/colab/blob/master/TFX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw88g3Y3XrOU",
        "colab_type": "text"
      },
      "source": [
        "The underlying tutorial is using the Titanic dataset to display a fully fleshed out TFX pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvTxFd18WpVe",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAi9rV3yXIiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO(ccy): remove \"pyzmq==17.0.0\" pin after bug in Colab is fixed.\n",
        "!pip install -q \"tfx>=0.21.1,<0.22\" \"tensorflow>=2.1,<2.2\" \"tensorboard>=2.1,<2.3\" \"pyzmq==17.0.0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JImbr3c3Rr36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import tfx\n",
        "\n",
        "# Helper libraries (non core)\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "# Create Interactive content\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "# ExampleGen\n",
        "from tfx.components import CsvExampleGen\n",
        "from tfx.utils.dsl_utils import external_input\n",
        "\n",
        "# StatisticsGen\n",
        "from tfx.components import StatisticsGen\n",
        "\n",
        "# SchemaGen\n",
        "from tfx.components import SchemaGen\n",
        "\n",
        "# ExampleValidator\n",
        "from tfx.components import ExampleValidator\n",
        "\n",
        "# Transform\n",
        "from tfx.components import Transform\n",
        "\n",
        "# Trainer\n",
        "from tfx.components import Trainer\n",
        "from tfx.components.base import executor_spec\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.proto import trainer_pb2\n",
        "\n",
        "# Evaluator\n",
        "import tensorflow_model_analysis as tfma\n",
        "from tfx.components import ResolverNode\n",
        "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model\n",
        "from tfx.types.standard_artifacts import ModelBlessing\n",
        "from tfx.components import Evaluator\n",
        "\n",
        "# Pusher\n",
        "from tfx.components import Pusher\n",
        "from tfx.proto import pusher_pb2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53K0Z2RVYqqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpleLoNT7-F",
        "colab_type": "text"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp58vGqgT7FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile _titanic_constants.py\n",
        "\n",
        "GITHUB_PATH = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "DATASET_PATH = './Data/dataset.csv'\n",
        "DATA_PATH = './Data'\n",
        "SERVING_MODEL_PATH = './Serving'\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = ['Fare']\n",
        "_CATEGORICAL_FEATURE_KEYS = ['Sex']\n",
        "_LABEL_KEY = 'Survived'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeyoCooDTtA9",
        "colab_type": "text"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWpl4jHyVl7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Data directory.\n",
        "\n",
        "# Data\n",
        "if not os.path.exists('./Data'):\n",
        "    os.makedirs('./Data')\n",
        "else:\n",
        "  shutil.rmtree('./Data')\n",
        "  os.makedirs('./Data')\n",
        "\n",
        "# Metadata\n",
        "if not os.path.exists('./Metadata'):\n",
        "    os.makedirs('./Metadata')\n",
        "else:\n",
        "  shutil.rmtree('./Metadata')\n",
        "  os.makedirs('./Metadata')\n",
        "\n",
        "# Metadata\n",
        "if not os.path.exists('./Serving'):\n",
        "    os.makedirs('./Serving')\n",
        "else:\n",
        "  shutil.rmtree('./Serving')\n",
        "  os.makedirs('./Serving')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDQ3PCdvTszu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import _titanic_constants as constants\n",
        "\n",
        "url = constants.GITHUB_PATH\n",
        "df = pd.read_csv(url, index_col=0)\n",
        "pd.DataFrame.to_csv(df, constants.DATASET_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aUXlblPVpO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Have a quick look at the data.\n",
        "!head {DATASET_PATH}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Jxhb0BWgUb",
        "colab_type": "text"
      },
      "source": [
        "# TFX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj4TCWSQWSwc",
        "colab_type": "text"
      },
      "source": [
        "## Create interactive content\n",
        "\n",
        "For this demo, we use the notebook itself as interactive scheduler ([Source](https://www.tensorflow.org/tfx/api_docs/python/tfx/orchestration/experimental/interactive/interactive_context/InteractiveContext))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEwBMePxWxqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = InteractiveContext(\n",
        "    pipeline_name = 'Titanic_Pipeline',\n",
        "    pipeline_root = './Metadata')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKvea-uraD3X",
        "colab_type": "text"
      },
      "source": [
        "## ExampleGen\n",
        "\n",
        "ExampleGen is used to ingest BigQuery, CSV and TFRecords data. Automatically converts those dataformats into TFRecords and creates training- and validation splits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIGd0C_wZsmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import _titanic_constants as constants\n",
        "\n",
        "example_gen = CsvExampleGen(input=external_input(constants.DATA_PATH))\n",
        "context.run(example_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FddFYBYEaZRp",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "\n",
        "# @To-Do: Make this nicer.\n",
        "\n",
        "# Get the URI of the output artifact representing the training examples, which is a directory\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  # pp.pprint(example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx_e5Z1Ede8R",
        "colab_type": "text"
      },
      "source": [
        "## StatisticsGen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AghjzYCgdfCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0l-IGhDgcip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print statistics.\n",
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gaxnE1Og0Qt",
        "colab_type": "text"
      },
      "source": [
        "## SchemaGen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-v71uBAg0WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "schema_gen = SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTRCT1nHhasL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zzIhlErhpT8",
        "colab_type": "text"
      },
      "source": [
        "## ExampleValidator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AUSstRShpNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_validator = ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBtEQXHzh7-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rt1EiMWiIB5",
        "colab_type": "text"
      },
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSK6fJ6HiIQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile _titanic_transform.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "import _titanic_constants as constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = constants._DENSE_FLOAT_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = constants._CATEGORICAL_FEATURE_KEYS\n",
        "_LABEL_KEY = constants._LABEL_KEY\n",
        "\n",
        "def _transformed_name(key):\n",
        "  # Renames transformed variables.\n",
        "  return key + '_xf'\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "  # Preprocess data with tft.\n",
        "  outputs = {}\n",
        "\n",
        "  for key in _DENSE_FLOAT_FEATURE_KEYS:\n",
        "    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n",
        "        _fill_in_missing(inputs[key]))\n",
        "\n",
        "  for key in _CATEGORICAL_FEATURE_KEYS:\n",
        "    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n",
        "\n",
        "  outputs[_transformed_name(_LABEL_KEY)] = _fill_in_missing(inputs[_LABEL_KEY])\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def _fill_in_missing(x):\n",
        "  \"\"\"Replace missing values in a SparseTensor.\n",
        "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "  Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "  Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "  \"\"\"\n",
        "  default_value = '' if x.dtype == tf.string else 0\n",
        "  return tf.squeeze(\n",
        "      tf.sparse.to_dense(\n",
        "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "          default_value),\n",
        "      axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAeTWu9vld43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath('_titanic_transform.py'))\n",
        "context.run(transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnANR8lerQKd",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "\n",
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF1Atg_L0Q6u",
        "colab_type": "text"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQqlr1SJrtcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile _titanic_trainer.py\n",
        "\n",
        "import os\n",
        "import absl\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "import _titanic_constants as constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = constants._DENSE_FLOAT_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = constants._CATEGORICAL_FEATURE_KEYS\n",
        "_LABEL_KEY = constants._LABEL_KEY\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "  \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
        "  return tf.data.TFRecordDataset(\n",
        "      filenames,\n",
        "      compression_type='GZIP')\n",
        "\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "  \"\"\"Returns a function that parses a serialized tf.Example and applies TFT.\"\"\"\n",
        "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "  @tf.function\n",
        "  def serve_tf_examples_fn(serialized_tf_examples):\n",
        "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "    feature_spec = tf_transform_output.raw_feature_spec()\n",
        "    feature_spec.pop(_LABEL_KEY)\n",
        "    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "    transformed_features = model.tft_layer(parsed_features)\n",
        "    transformed_features.pop('Survived_xf')\n",
        "    \n",
        "    return model(transformed_features)\n",
        "  \n",
        "  return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern, tf_transform_output, batch_size):\n",
        "  \"\"\"Input function for training\"\"\"\n",
        "  transformed_feature_spec = (\n",
        "      tf_transform_output.transformed_feature_spec().copy())\n",
        "\n",
        "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "      file_pattern=file_pattern,\n",
        "      batch_size=batch_size,\n",
        "      features=transformed_feature_spec,\n",
        "      reader=_gzip_reader_fn,\n",
        "      label_key='Survived_xf')\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "\n",
        "\"\"\"BUILD MODEL\"\"\"\n",
        "def _build_keras_model():\n",
        "  # Define feature columns.\n",
        "  real_valued_columns = [tf.feature_column.numeric_column('Fare_xf')]\n",
        "\n",
        "  indicator_column = [tf.feature_column.indicator_column(\n",
        "      tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "          'Sex_xf', [\"male\", \"female\"]))]\n",
        "\n",
        "  # Defining the input layers.\n",
        "  input_layers = {\n",
        "      'Fare_xf': tf.keras.layers.Input(name='Fare_xf', shape=(), dtype=tf.float32)\n",
        "      \n",
        "  }\n",
        "  input_layers.update({\n",
        "      'Sex_xf': tf.keras.layers.Input(name='Sex_xf', shape=(), dtype='string')\n",
        "  })\n",
        "\n",
        "  # Build Keras model.\n",
        "  deep = tf.keras.layers.DenseFeatures(real_valued_columns)(input_layers)\n",
        "  wide = tf.keras.layers.DenseFeatures(indicator_column)(input_layers)\n",
        "  merged_layers = tf.keras.layers.concatenate([deep, wide])\n",
        "  output = tf.keras.layers.Dense(1, activation='sigmoid')(merged_layers)\n",
        "  model = tf.keras.Model(input_layers, output)\n",
        "\n",
        "  # Compile model.\n",
        "  model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "  model.summary(print_fn=absl.logging.info)\n",
        "  return model\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "  train_dataset = _input_fn(fn_args.train_files, tf_transform_output, 40)\n",
        "  eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, 40)\n",
        "\n",
        "  model = _build_keras_model()\n",
        "\n",
        "  # This log path might change in the future.\n",
        "  log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')\n",
        "  \n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir, update_freq='batch')\n",
        "  \n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps,\n",
        "      callbacks=[tensorboard_callback])\n",
        "\n",
        "  # To-Do: I still do not understand this part.\n",
        "  signatures = {\n",
        "      'serving_default':\n",
        "          _get_serve_tf_examples_fn(model,\n",
        "                                    tf_transform_output).get_concrete_function(\n",
        "                                        tf.TensorSpec(\n",
        "                                            shape=[None],\n",
        "                                            dtype=tf.string,\n",
        "                                            name='examples')),\n",
        "  }\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyip7D21seHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = Trainer(\n",
        "    module_file=os.path.abspath('_titanic_trainer.py'),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=6000))\n",
        "context.run(trainer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2e4MmHmw_UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_artifact_dir = trainer.outputs['model'].get()[0].uri\n",
        "log_dir = os.path.join(model_artifact_dir, 'logs')\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OEmK7Tfxhr1",
        "colab_type": "text"
      },
      "source": [
        "## Evaluator\n",
        "\n",
        "The following [code](https://www.tensorflow.org/tfx/model_analysis/metrics?hl=de) was used for the binary setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ry-H_Ofxhxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        tfma.ModelSpec(label_key='Survived')\n",
        "    ],\n",
        "    metrics_specs = tfma.metrics.specs_from_metrics(\n",
        "        [\n",
        "               tfma.metrics.ExampleCount(name='example_count'),\n",
        "               tfma.metrics.WeightedExampleCount(name='weighted_example_count'),\n",
        "               tf.keras.metrics.BinaryCrossentropy(name='binary_crossentropy'),\n",
        "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "               tf.keras.metrics.AUC(name='auc', num_thresholds=10000),\n",
        "               tf.keras.metrics.AUC(\n",
        "                   name='auc_precision_recall', curve='PR', num_thresholds=10000),\n",
        "               tf.keras.metrics.Precision(name='precision'),\n",
        "               tf.keras.metrics.Recall(name='recall'),\n",
        "               tfma.metrics.MeanLabel(name='mean_label'),\n",
        "               tfma.metrics.MeanPrediction(name='mean_prediction'),\n",
        "               tfma.metrics.Calibration(name='calibration'),\n",
        "               tfma.metrics.ConfusionMatrixPlot(name='confusion_matrix_plot'),\n",
        "               tfma.metrics.CalibrationPlot(name='calibration_plot')\n",
        "               ]\n",
        "    ),\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "        # Data can be sliced along a feature column. In this case, data is\n",
        "        # sliced along feature column trip_start_hour.\n",
        "        tfma.SlicingSpec(feature_keys=['Sex'])\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_vam09wyasP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This part is still experimental.'''\n",
        "model_resolver = ResolverNode(\n",
        "      instance_name='latest_blessed_model_resolver',\n",
        "      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
        "      model=Channel(type=Model),\n",
        "      model_blessing=Channel(type=ModelBlessing))\n",
        "context.run(model_resolver)\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    # Change threshold will be ignored if there is no baseline (first run).\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Uaj_oJztCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Overall model evaluation.\n",
        "context.show(evaluator.outputs['evaluation'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuEh88vrz9yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model evaluation according to certain metrics.\n",
        "\n",
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(tfma_result, slicing_column='Sex')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7pmkAZ74BEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYZKQpcV4P_3",
        "colab_type": "text"
      },
      "source": [
        "## Pusher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxduvKy4QFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import _titanic_constants as constants\n",
        "\n",
        "pusher = Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=pusher_pb2.PushDestination(\n",
        "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "            base_directory=constants.SERVING_MODEL_PATH)))\n",
        "context.run(pusher)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc38j_LWjp0D",
        "colab_type": "text"
      },
      "source": [
        "# Export the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS72KA8Hjp6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys \n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  # Colab.\n",
        "  from google.colab import drive\n",
        "\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzcoK22ukBbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNGaE8zJj47T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_runner_type = 'beam' \n",
        "_pipeline_name = 'chicago_taxi_%s' % _runner_type\n",
        "\n",
        "\n",
        "_notebook_filepath = ('/content/drive/My Drive/Colab Notebooks/TFX.ipynb')\n",
        "\n",
        "\n",
        "_tfx_root = os.path.join(os.environ['HOME'], 'tfx')\n",
        "_taxi_root = os.path.join(os.environ['HOME'], 'taxi')\n",
        "_serving_model_dir = os.path.join(_taxi_root, 'serving_model')\n",
        "_data_root = os.path.join(_taxi_root, 'data', 'simple')\n",
        "_pipeline_root = os.path.join(_tfx_root, 'pipelines', _pipeline_name)\n",
        "_metadata_path = os.path.join(_tfx_root, 'metadata', _pipeline_name,\n",
        "                              'metadata.db')\n",
        "\n",
        "# TODO(USER): Specify components to be included in the exported pipeline.\n",
        "components = [\n",
        "    example_gen, statistics_gen, schema_gen, example_validator, transform,\n",
        "    trainer, evaluator, pusher\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "if get_ipython().magics_manager.auto_magic:\n",
        "  print('Warning: %automagic is ON. Line magics specified without the % prefix '\n",
        "        'will not be scrubbed during export to pipeline.')\n",
        "\n",
        "_pipeline_export_filepath = 'export_%s.py' % _pipeline_name\n",
        "context.export_to_pipeline(notebook_filepath=_notebook_filepath,\n",
        "                           export_filepath=_pipeline_export_filepath,\n",
        "                           runner_type=_runner_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7PwIrdhlQh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tempfile\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import files\n",
        "  import zipfile\n",
        "\n",
        "  zip_export_path = os.path.join(\n",
        "      tempfile.mkdtemp(), 'export.zip')\n",
        "  with zipfile.ZipFile(zip_export_path, mode='w') as export_zip:\n",
        "    export_zip.write(_pipeline_export_filepath)\n",
        "    export_zip.write(_titanic_constants)\n",
        "\n",
        "\n",
        "  files.download(zip_export_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}