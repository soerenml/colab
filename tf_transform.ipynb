{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_transform.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOZXe008fLWyilf8th8QG9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soerenml/colab/blob/master/tf_transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9X6mulG0U6k",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Transform (`tft`)\n",
        "\n",
        "`tft` is needed once a ML projects reaches professional production status. tft uses `Beam` for data transformation. This allows the user to: use the full power of `Beam` (batch streaming data); scale out horizontally (if Beam is used with Flink or Dataflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL012W8z0_fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip uninstall tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klQt7uwa1AIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install tensorflow==2.1.0 tfx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGvyKPoI1CIA",
        "colab_type": "code",
        "outputId": "e9f3a58a-a84e-4bc4-868b-cf6d777d1b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Restart runtime\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEJ4HFCu4Chh",
        "colab_type": "code",
        "outputId": "db772a07-e02f-4d75-bff3-c93f4ae25d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip uninstall tensorflow-transform\n",
        "!pip uninstall apache-beam"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-transform-0.21.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_transform-0.21.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_transform/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-transform-0.21.0\n",
            "Uninstalling apache-beam-2.17.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/apache_beam-2.17.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/apache_beam/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled apache-beam-2.17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgMdHKRw0IXj",
        "colab_type": "code",
        "outputId": "46d54c8d-f957-4368-ad45-79d843fa1f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Restart runtime and run again\n",
        "import argparse\n",
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version: {} '.format(tf.__version__))\n",
        "\n",
        "print(\"Installing dependencies for Colab environment\")\n",
        "!pip install -q -Uq grpcio==1.26.0\n",
        "\n",
        "print('Installing Apache Beam')\n",
        "!pip install -q -Uq apache_beam==2.16.0\n",
        "import apache_beam as beam\n",
        "\n",
        "print('Installing TensorFlow Transform')\n",
        "!pip install -q -Uq tensorflow-transform==0.15.0\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import apache_beam.io.iobase\n",
        "import tensorflow_transform.beam as tft_beam\n",
        "from tensorflow_transform.tf_metadata import dataset_metadata\n",
        "from tensorflow_transform.tf_metadata import dataset_schema"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.1.0 \n",
            "Installing dependencies for Colab environment\n",
            "Installing Apache Beam\n",
            "Installing TensorFlow Transform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uHYOSWBzJe6",
        "colab_type": "text"
      },
      "source": [
        "In the demo, the link for import does not work. Download the census from the [website](https://archive.ics.uci.edu/ml/datasets/US+Census+Data+%281990%29) instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg2p6EpV5n0z",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OGTi90n0fP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "340b6573-2706-4425-c022-b77df52728e3"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "  shutil.rmtree('temp')\n",
        "  os.mkdir('tempd')\n",
        "  print('Deleted and created dir')\n",
        "except:\n",
        "  os.mkdir('temp')\n",
        "  print('Created dir')\n",
        "\n",
        "temp = 'temp'\n",
        "train = os.path.join('adult.data')\n",
        "test = os.path.join('adult.test')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujxQUcgN6BFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORICAL_FEATURE_KEYS = [\n",
        "    'workclass',\n",
        "    'education',\n",
        "    'marital-status',\n",
        "    'occupation',\n",
        "    'relationship',\n",
        "    'race',\n",
        "    'sex',\n",
        "    'native-country',\n",
        "]\n",
        "NUMERIC_FEATURE_KEYS = [\n",
        "    'age',\n",
        "    'capital-gain',\n",
        "    'capital-loss',\n",
        "    'hours-per-week',\n",
        "]\n",
        "OPTIONAL_NUMERIC_FEATURE_KEYS = [\n",
        "    'education-num',\n",
        "]\n",
        "LABEL_KEY = 'label'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZRojGJCCWrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3bf052b3-9446-4540-89e9-74dd17e0bb82"
      },
      "source": [
        "RAW_DATA_FEATURE_SPEC = dict(\n",
        "    [(name, tf.io.FixedLenFeature([], tf.string))\n",
        "     for name in CATEGORICAL_FEATURE_KEYS] +\n",
        "    [(name, tf.io.FixedLenFeature([], tf.float32))\n",
        "     for name in NUMERIC_FEATURE_KEYS] +\n",
        "    [(name, tf.io.VarLenFeature(tf.float32))\n",
        "     for name in OPTIONAL_NUMERIC_FEATURE_KEYS] +\n",
        "    [(LABEL_KEY, tf.io.FixedLenFeature([], tf.string))]\n",
        ")\n",
        "\n",
        "RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(\n",
        "    dataset_schema.from_feature_spec(RAW_DATA_FEATURE_SPEC))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-c632e5aa37a7>:12: from_feature_spec (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "from_feature_spec is a deprecated, use schema_utils.schema_from_feature_spec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-c632e5aa37a7>:12: from_feature_spec (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "from_feature_spec is a deprecated, use schema_utils.schema_from_feature_spec\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpjq9JJ97Vs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing = os.getenv(\"WEB_TEST_BROWSER\", False)\n",
        "if testing:\n",
        "  TRAIN_NUM_EPOCHS = 1\n",
        "  NUM_TRAIN_INSTANCES = 1\n",
        "  TRAIN_BATCH_SIZE = 1\n",
        "  NUM_TEST_INSTANCES = 1\n",
        "else:\n",
        "  TRAIN_NUM_EPOCHS = 16\n",
        "  NUM_TRAIN_INSTANCES = 32561\n",
        "  TRAIN_BATCH_SIZE = 128\n",
        "  NUM_TEST_INSTANCES = 16281\n",
        "\n",
        "# Names of temp files\n",
        "TRANSFORMED_TRAIN_DATA_FILEBASE = 'train_transformed'\n",
        "TRANSFORMED_TEST_DATA_FILEBASE = 'test_transformed'\n",
        "EXPORTED_MODEL_DIR = 'exported_model_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5NGk7m-7icf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MapAndFilterErrors(beam.PTransform):\n",
        "  \"\"\"Like beam.Map but filters out errors in the map_fn.\"\"\"\n",
        "\n",
        "  class _MapAndFilterErrorsDoFn(beam.DoFn):\n",
        "    \"\"\"Count the bad examples using a beam metric.\"\"\"\n",
        "\n",
        "    def __init__(self, fn):\n",
        "      self._fn = fn\n",
        "      # Create a counter to measure number of bad elements.\n",
        "      self._bad_elements_counter = beam.metrics.Metrics.counter(\n",
        "          'census_example', 'bad_elements')\n",
        "\n",
        "    def process(self, element):\n",
        "      try:\n",
        "        yield self._fn(element)\n",
        "      except Exception:  # pylint: disable=broad-except\n",
        "        # Catch any exception the above call.\n",
        "        self._bad_elements_counter.inc(1)\n",
        "\n",
        "  def __init__(self, fn):\n",
        "    self._fn = fn\n",
        "\n",
        "  def expand(self, pcoll):\n",
        "    return pcoll | beam.ParDo(self._MapAndFilterErrorsDoFn(self._fn))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgDAIQ9r7mNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"Preprocess input columns into transformed columns.\"\"\"\n",
        "  # Since we are modifying some features and leaving others unchanged, we\n",
        "  # start by setting `outputs` to a copy of `inputs.\n",
        "  outputs = inputs.copy()\n",
        "\n",
        "  # Scale numeric columns to have range [0, 1].\n",
        "  for key in NUMERIC_FEATURE_KEYS:\n",
        "    outputs[key] = tft.scale_to_0_1(outputs[key])\n",
        "\n",
        "  for key in OPTIONAL_NUMERIC_FEATURE_KEYS:\n",
        "    # This is a SparseTensor because it is optional. Here we fill in a default\n",
        "    # value when it is missing.\n",
        "    sparse = tf.sparse.SparseTensor(outputs[key].indices, outputs[key].values,\n",
        "                                    [outputs[key].dense_shape[0], 1])\n",
        "    dense = tf.sparse.to_dense(sp_input=sparse, default_value=0.)\n",
        "    # Reshaping from a batch of vectors of size 1 to a batch to scalars.\n",
        "    dense = tf.squeeze(dense, axis=1)\n",
        "    outputs[key] = tft.scale_to_0_1(dense)\n",
        "\n",
        "    # For all categorical columns except the label column, we generate a\n",
        "    # vocabulary but do not modify the feature.  This vocabulary is instead\n",
        "    # used in the trainer, by means of a feature column, to convert the feature\n",
        "    # from a string to an integer id.\n",
        "    for key in CATEGORICAL_FEATURE_KEYS:\n",
        "      tft.vocabulary(inputs[key], vocab_filename=key)\n",
        "\n",
        "    # For the label column we provide the mapping from string to index.\n",
        "    table_keys = ['>50K', '<=50K']\n",
        "    initializer = tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=table_keys,\n",
        "        values=tf.cast(tf.range(len(table_keys)), tf.int64),\n",
        "        key_dtype=tf.string,\n",
        "        value_dtype=tf.int64)\n",
        "    table = tf.lookup.StaticHashTable(initializer, default_value=-1)\n",
        "    outputs[LABEL_KEY] = table.lookup(outputs[LABEL_KEY])\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx_L6k0c8BdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_data(train_data_file, test_data_file, working_dir):\n",
        "  \"\"\"Transform the data and write out as a TFRecord of Example protos.\n",
        "\n",
        "  Read in the data using the CSV reader, and transform it using a\n",
        "  preprocessing pipeline that scales numeric data and converts categorical data\n",
        "  from strings to int64 values indices, by creating a vocabulary for each\n",
        "  category.\n",
        "\n",
        "  Args:\n",
        "    train_data_file: File containing training data\n",
        "    test_data_file: File containing test data\n",
        "    working_dir: Directory to write transformed data and metadata to\n",
        "  \"\"\"\n",
        "\n",
        "  # The \"with\" block will create a pipeline, and run that pipeline at the exit\n",
        "  # of the block.\n",
        "  with beam.Pipeline() as pipeline:\n",
        "    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
        "      # Create a coder to read the census data with the schema.  To do this we\n",
        "      # need to list all columns in order since the schema doesn't specify the\n",
        "      # order of columns in the csv.\n",
        "      ordered_columns = [\n",
        "          'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "          'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "          'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
        "          'label'\n",
        "      ]\n",
        "      converter = tft.coders.CsvCoder(ordered_columns, RAW_DATA_METADATA.schema)\n",
        "\n",
        "      # Read in raw data and convert using CSV converter.  Note that we apply\n",
        "      # some Beam transformations here, which will not be encoded in the TF\n",
        "      # graph since we don't do them from within tf.Transform's methods\n",
        "      # (AnalyzeDataset, TransformDataset etc.).  These transformations are just\n",
        "      # to get data into a format that the CSV converter can read, in particular\n",
        "      # removing spaces after commas.\n",
        "      #\n",
        "      # We use MapAndFilterErrors instead of Map to filter out decode errors in\n",
        "      # convert.decode which should only occur for the trailing blank line.\n",
        "      raw_data = (\n",
        "          pipeline\n",
        "          | 'ReadTrainData' >> beam.io.ReadFromText(train_data_file)\n",
        "          | 'FixCommasTrainData' >> beam.Map(\n",
        "              lambda line: line.replace(', ', ','))\n",
        "          | 'DecodeTrainData' >> MapAndFilterErrors(converter.decode))\n",
        "\n",
        "      # Combine data and schema into a dataset tuple.  Note that we already used\n",
        "      # the schema to read the CSV data, but we also need it to interpret\n",
        "      # raw_data.\n",
        "      raw_dataset = (raw_data, RAW_DATA_METADATA)\n",
        "      transformed_dataset, transform_fn = (\n",
        "          raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n",
        "      transformed_data, transformed_metadata = transformed_dataset\n",
        "      transformed_data_coder = tft.coders.ExampleProtoCoder(\n",
        "          transformed_metadata.schema)\n",
        "\n",
        "      _ = (\n",
        "          transformed_data\n",
        "          | 'EncodeTrainData' >> beam.Map(transformed_data_coder.encode)\n",
        "          | 'WriteTrainData' >> beam.io.WriteToTFRecord(\n",
        "              os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE)))\n",
        "\n",
        "      # Now apply transform function to test data.  In this case we remove the\n",
        "      # trailing period at the end of each line, and also ignore the header line\n",
        "      # that is present in the test data file.\n",
        "      raw_test_data = (\n",
        "          pipeline\n",
        "          | 'ReadTestData' >> beam.io.ReadFromText(test_data_file,\n",
        "                                                   skip_header_lines=1)\n",
        "          | 'FixCommasTestData' >> beam.Map(\n",
        "              lambda line: line.replace(', ', ','))\n",
        "          | 'RemoveTrailingPeriodsTestData' >> beam.Map(lambda line: line[:-1])\n",
        "          | 'DecodeTestData' >> MapAndFilterErrors(converter.decode))\n",
        "\n",
        "      raw_test_dataset = (raw_test_data, RAW_DATA_METADATA)\n",
        "\n",
        "      transformed_test_dataset = (\n",
        "          (raw_test_dataset, transform_fn) | tft_beam.TransformDataset())\n",
        "      # Don't need transformed data schema, it's the same as before.\n",
        "      transformed_test_data, _ = transformed_test_dataset\n",
        "\n",
        "      _ = (\n",
        "          transformed_test_data\n",
        "          | 'EncodeTestData' >> beam.Map(transformed_data_coder.encode)\n",
        "          | 'WriteTestData' >> beam.io.WriteToTFRecord(\n",
        "              os.path.join(working_dir, TRANSFORMED_TEST_DATA_FILEBASE)))\n",
        "\n",
        "      # Will write a SavedModel and metadata to working_dir, which can then\n",
        "      # be read by the tft.TFTransformOutput class.\n",
        "      _ = (\n",
        "          transform_fn\n",
        "          | 'WriteTransformFn' >> tft_beam.WriteTransformFn(working_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGiejimP8kYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _make_training_input_fn(tf_transform_output, transformed_examples,\n",
        "                            batch_size):\n",
        "  \"\"\"Creates an input function reading from transformed data.\n",
        "\n",
        "  Args:\n",
        "    tf_transform_output: Wrapper around output of tf.Transform.\n",
        "    transformed_examples: Base filename of examples.\n",
        "    batch_size: Batch size.\n",
        "\n",
        "  Returns:\n",
        "    The input function for training or eval.\n",
        "  \"\"\"\n",
        "  def input_fn():\n",
        "    \"\"\"Input function for training and eval.\"\"\"\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=transformed_examples,\n",
        "        batch_size=batch_size,\n",
        "        features=tf_transform_output.transformed_feature_spec(),\n",
        "        reader=tf.data.TFRecordDataset,\n",
        "        shuffle=True)\n",
        "\n",
        "    transformed_features = tf.compat.v1.data.make_one_shot_iterator(\n",
        "        dataset).get_next()\n",
        "\n",
        "    # Extract features and label from the transformed tensors.\n",
        "    transformed_labels = transformed_features.pop(LABEL_KEY)\n",
        "\n",
        "    return transformed_features, transformed_labels\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3dIqW-q8nhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _make_serving_input_fn(tf_transform_output):\n",
        "  \"\"\"Creates an input function reading from raw data.\n",
        "\n",
        "  Args:\n",
        "    tf_transform_output: Wrapper around output of tf.Transform.\n",
        "\n",
        "  Returns:\n",
        "    The serving input function.\n",
        "  \"\"\"\n",
        "  raw_feature_spec = RAW_DATA_FEATURE_SPEC.copy()\n",
        "  # Remove label since it is not available during serving.\n",
        "  raw_feature_spec.pop(LABEL_KEY)\n",
        "\n",
        "  def serving_input_fn():\n",
        "    \"\"\"Input function for serving.\"\"\"\n",
        "    # Get raw features by generating the basic serving input_fn and calling it.\n",
        "    # Here we generate an input_fn that expects a parsed Example proto to be fed\n",
        "    # to the model at serving time.  See also\n",
        "    # tf.estimator.export.build_raw_serving_input_receiver_fn.\n",
        "    raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "        raw_feature_spec, default_batch_size=None)\n",
        "    serving_input_receiver = raw_input_fn()\n",
        "\n",
        "    # Apply the transform function that was used to generate the materialized\n",
        "    # data.\n",
        "    raw_features = serving_input_receiver.features\n",
        "    transformed_features = tf_transform_output.transform_raw_features(\n",
        "        raw_features)\n",
        "\n",
        "    return tf.estimator.export.ServingInputReceiver(\n",
        "        transformed_features, serving_input_receiver.receiver_tensors)\n",
        "\n",
        "  return serving_input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPNi-me8rHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_columns(tf_transform_output):\n",
        "  \"\"\"Returns the FeatureColumns for the model.\n",
        "\n",
        "  Args:\n",
        "    tf_transform_output: A `TFTransformOutput` object.\n",
        "\n",
        "  Returns:\n",
        "    A list of FeatureColumns.\n",
        "  \"\"\"\n",
        "  # Wrap scalars as real valued columns.\n",
        "  real_valued_columns = [tf.feature_column.numeric_column(key, shape=())\n",
        "                         for key in NUMERIC_FEATURE_KEYS]\n",
        "\n",
        "  # Wrap categorical columns.\n",
        "  one_hot_columns = [\n",
        "      tf.feature_column.categorical_column_with_vocabulary_file(\n",
        "          key=key,\n",
        "          vocabulary_file=tf_transform_output.vocabulary_file_by_name(\n",
        "              vocab_filename=key))\n",
        "      for key in CATEGORICAL_FEATURE_KEYS]\n",
        "\n",
        "  return real_valued_columns + one_hot_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuwyRujV8uFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_evaluate(working_dir, num_train_instances=NUM_TRAIN_INSTANCES,\n",
        "                       num_test_instances=NUM_TEST_INSTANCES):\n",
        "  \"\"\"Train the model on training data and evaluate on test data.\n",
        "\n",
        "  Args:\n",
        "    working_dir: Directory to read transformed data and metadata from and to\n",
        "        write exported model to.\n",
        "    num_train_instances: Number of instances in train set\n",
        "    num_test_instances: Number of instances in test set\n",
        "\n",
        "  Returns:\n",
        "    The results from the estimator's 'evaluate' method\n",
        "  \"\"\"\n",
        "  tf_transform_output = tft.TFTransformOutput(working_dir)\n",
        "\n",
        "  run_config = tf.estimator.RunConfig()\n",
        "\n",
        "  estimator = tf.estimator.LinearClassifier(\n",
        "      feature_columns=get_feature_columns(tf_transform_output),\n",
        "      config=run_config,\n",
        "      loss_reduction=tf.losses.Reduction.SUM)\n",
        "\n",
        "  # Fit the model using the default optimizer.\n",
        "  train_input_fn = _make_training_input_fn(\n",
        "      tf_transform_output,\n",
        "      os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE + '*'),\n",
        "      batch_size=TRAIN_BATCH_SIZE)\n",
        "  estimator.train(\n",
        "      input_fn=train_input_fn,\n",
        "      max_steps=TRAIN_NUM_EPOCHS * num_train_instances / TRAIN_BATCH_SIZE)\n",
        "\n",
        "  # Evaluate model on test dataset.\n",
        "  eval_input_fn = _make_training_input_fn(\n",
        "      tf_transform_output,\n",
        "      os.path.join(working_dir, TRANSFORMED_TEST_DATA_FILEBASE + '*'),\n",
        "      batch_size=1)\n",
        "\n",
        "  # Export the model.\n",
        "  serving_input_fn = _make_serving_input_fn(tf_transform_output)\n",
        "  exported_model_dir = os.path.join(working_dir, EXPORTED_MODEL_DIR)\n",
        "  estimator.export_saved_model(exported_model_dir, serving_input_fn)\n",
        "\n",
        "  return estimator.evaluate(input_fn=eval_input_fn, steps=num_test_instances)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KK4zqLw8zYq",
        "colab_type": "code",
        "outputId": "50883c98-1d04-4247-da8f-a28cccd5bc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "transform_data(train, test, temp)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /tmp/tmp7ico7z3l/tftransform_tmp/ede9633725e748258542bd08e833f59b/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /tmp/tmp7ico7z3l/tftransform_tmp/ede9633725e748258542bd08e833f59b/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /tmp/tmp7ico7z3l/tftransform_tmp/6ccbd18fa3cb4b2a91923a36c2b843f7/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /tmp/tmp7ico7z3l/tftransform_tmp/6ccbd18fa3cb4b2a91923a36c2b843f7/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7ico7z3l/tftransform_tmp/0e886bc0c4a849ceb42b7df61f8c3ba9/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7ico7z3l/tftransform_tmp/0e886bc0c4a849ceb42b7df61f8c3ba9/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /tmp/tmp7ico7z3l/tftransform_tmp/0e886bc0c4a849ceb42b7df61f8c3ba9/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /tmp/tmp7ico7z3l/tftransform_tmp/0e886bc0c4a849ceb42b7df61f8c3ba9/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "WARNING:root:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygc-v1ijBZ4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7ec3dc0-396b-4a40-f326-2a4bed933202"
      },
      "source": [
        "results = train_and_evaluate(temp)\n",
        "pprint.pprint(results)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 9 in workclass is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/workclass.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 9 in workclass is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/workclass.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 16 in education is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/education.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 16 in education is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/education.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 7 in marital-status is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/marital-status.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 7 in marital-status is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/marital-status.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 15 in occupation is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/occupation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 15 in occupation is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/occupation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 6 in relationship is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/relationship.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 6 in relationship is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/relationship.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 5 in race is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/race.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 5 in race is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/race.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 2 in sex is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/sex.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 2 in sex is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/sex.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 42 in native-country is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/native-country.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 42 in native-country is inferred from the number of elements in the vocabulary_file temp/transform_fn/assets/native-country.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpanq543uv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpanq543uv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpanq543uv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpanq543uv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpanq543uv/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpanq543uv/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 88.722855, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 88.722855, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 154.346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 154.346\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.18338, step = 100 (0.650 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.18338, step = 100 (0.650 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 115 vs previous value: 115. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 115 vs previous value: 115. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 303.667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 303.667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.213993, step = 200 (0.333 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.213993, step = 200 (0.333 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 307.966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 307.966\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 51.216343, step = 300 (0.321 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 51.216343, step = 300 (0.321 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 315.025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 315.025\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.585316, step = 400 (0.322 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.585316, step = 400 (0.322 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 303.026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 303.026\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 53.245567, step = 500 (0.332 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 53.245567, step = 500 (0.332 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 316.93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 316.93\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 49.42384, step = 600 (0.309 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 49.42384, step = 600 (0.309 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 320.082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 320.082\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.115337, step = 700 (0.316 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.115337, step = 700 (0.316 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 314.909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 314.909\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.524094, step = 800 (0.320 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.524094, step = 800 (0.320 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 319.522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 319.522\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.201004, step = 900 (0.310 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.201004, step = 900 (0.310 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 301.159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 301.159\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 39.652813, step = 1000 (0.334 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 39.652813, step = 1000 (0.334 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 289.718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 289.718\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 40.565514, step = 1100 (0.344 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 40.565514, step = 1100 (0.344 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 302.36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 302.36\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.57085, step = 1200 (0.329 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.57085, step = 1200 (0.329 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 309.835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 309.835\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.92079, step = 1300 (0.326 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.92079, step = 1300 (0.326 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 318.998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 318.998\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 45.84387, step = 1400 (0.315 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 45.84387, step = 1400 (0.315 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 296.361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 296.361\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 49.994232, step = 1500 (0.337 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 49.994232, step = 1500 (0.337 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 296.66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 296.66\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.66858, step = 1600 (0.333 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.66858, step = 1600 (0.333 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 306.618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 306.618\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 36.12761, step = 1700 (0.325 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 36.12761, step = 1700 (0.325 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 289.631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 289.631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.40558, step = 1800 (0.350 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.40558, step = 1800 (0.350 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 290.028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 290.028\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 36.847687, step = 1900 (0.348 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 36.847687, step = 1900 (0.348 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 277.383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 277.383\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 35.716644, step = 2000 (0.360 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 35.716644, step = 2000 (0.360 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 302.136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 302.136\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 32.44583, step = 2100 (0.325 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 32.44583, step = 2100 (0.325 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 299.629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 299.629\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 33.87439, step = 2200 (0.333 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 33.87439, step = 2200 (0.333 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 316.458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 316.458\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 54.476288, step = 2300 (0.316 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 54.476288, step = 2300 (0.316 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 323.452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 323.452\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.47, step = 2400 (0.310 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.47, step = 2400 (0.310 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.184\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 45.101326, step = 2500 (0.340 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 45.101326, step = 2500 (0.340 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 307.172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 307.172\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 44.302155, step = 2600 (0.324 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 44.302155, step = 2600 (0.324 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 312.839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 312.839\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.249115, step = 2700 (0.320 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 41.249115, step = 2700 (0.320 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 293.955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 293.955\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.923088, step = 2800 (0.336 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.923088, step = 2800 (0.336 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 316.585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 316.585\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 29.920012, step = 2900 (0.316 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 29.920012, step = 2900 (0.316 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 323.906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 323.906\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.164986, step = 3000 (0.313 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 37.164986, step = 3000 (0.313 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.892\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 36.16698, step = 3100 (0.331 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 36.16698, step = 3100 (0.331 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 311.19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 311.19\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.97471, step = 3200 (0.321 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.97471, step = 3200 (0.321 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 321.518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 321.518\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 50.548462, step = 3300 (0.321 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 50.548462, step = 3300 (0.321 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 46.50028, step = 3400 (0.329 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 46.50028, step = 3400 (0.329 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 312.344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 312.344\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 47.78898, step = 3500 (0.318 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 47.78898, step = 3500 (0.318 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 289.017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 289.017\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 55.21965, step = 3600 (0.346 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 55.21965, step = 3600 (0.346 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 300.075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 300.075\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 35.994213, step = 3700 (0.334 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 35.994213, step = 3700 (0.334 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 297.417\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 45.424736, step = 3800 (0.337 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 45.424736, step = 3800 (0.337 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 319.644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 319.644\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.329082, step = 3900 (0.313 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 43.329082, step = 3900 (0.313 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 325.133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 325.133\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.069023, step = 4000 (0.311 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 38.069023, step = 4000 (0.311 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4071 into /tmp/tmpanq543uv/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4071 into /tmp/tmpanq543uv/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 42.294273.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 42.294273.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_2:0\\022\\016marital-status\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_3:0\\022\\noccupation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_6:0\\022\\014relationship\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\013\\n\\tConst_7:0\\022\\004race\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_10:0\\022\\003sex\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_11:0\\022\\016native-country\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_16:0\\022\\tworkclass\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
            "value: \"\\n\\014\\n\\nConst_17:0\\022\\teducation\"\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpanq543uv/model.ckpt-4071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpanq543uv/model.ckpt-4071\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: temp/exported_model_dir/temp-b'1582461257'/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: temp/exported_model_dir/temp-b'1582461257'/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: temp/exported_model_dir/temp-b'1582461257'/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: temp/exported_model_dir/temp-b'1582461257'/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-02-23T12:34:20Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-02-23T12:34:20Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpanq543uv/model.ckpt-4071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpanq543uv/model.ckpt-4071\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [1628/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [1628/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [3256/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [3256/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [4884/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [4884/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [6512/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [6512/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [8140/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [8140/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [9768/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [9768/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [11396/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [11396/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [13024/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [13024/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [14652/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [14652/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [16280/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [16280/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [16281/16281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [16281/16281]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inference Time : 20.31956s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inference Time : 20.31956s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-02-23-12:34:41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-02-23-12:34:41\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 4071: accuracy = 0.850562, accuracy_baseline = 0.76377374, auc = 0.90163505, auc_precision_recall = 0.9671197, average_loss = 0.32442203, global_step = 4071, label/mean = 0.76377374, loss = 0.32442203, precision = 0.87771904, prediction/mean = 0.7641811, recall = 0.9345396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 4071: accuracy = 0.850562, accuracy_baseline = 0.76377374, auc = 0.90163505, auc_precision_recall = 0.9671197, average_loss = 0.32442203, global_step = 4071, label/mean = 0.76377374, loss = 0.32442203, precision = 0.87771904, prediction/mean = 0.7641811, recall = 0.9345396\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4071: /tmp/tmpanq543uv/model.ckpt-4071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4071: /tmp/tmpanq543uv/model.ckpt-4071\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.850562,\n",
            " 'accuracy_baseline': 0.76377374,\n",
            " 'auc': 0.90163505,\n",
            " 'auc_precision_recall': 0.9671197,\n",
            " 'average_loss': 0.32442203,\n",
            " 'global_step': 4071,\n",
            " 'label/mean': 0.76377374,\n",
            " 'loss': 0.32442203,\n",
            " 'precision': 0.87771904,\n",
            " 'prediction/mean': 0.7641811,\n",
            " 'recall': 0.9345396}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}